{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the JSON files into more usable formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load json file and convert it to a pandas dataframe\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process JSON data into numpy picked files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json files and convert them into numpy arrays\n",
    "\n",
    "directory = 'uncombined-training-data/time-freq-1-mil/1-milisecond-positive-json-data/'\n",
    "all_positive = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(directory + filename) as f:\n",
    "            data = json.load(f)\n",
    "            # go through the data and convert it to a numpy array\n",
    "            for row in data:\n",
    "                row_list_with_label = []\n",
    "                row_list_with_label.append(1)\n",
    "                for col in row:\n",
    "                    row_list_with_label.append([float(col[\"x\"]), float(col[\"y\"]), float(col[\"z\"])])\n",
    "            all_positive.append(row_list_with_label)                    \n",
    "\n",
    "save_np_array = np.array(all_positive)\n",
    "\n",
    "# save the numpy array to a file\n",
    "np.save('positive.npy', save_np_array)\n",
    "\n",
    "directory = 'uncombined-training-data/time-freq-1-mil/1-milisecond-negative-json-data/'\n",
    "all_negative = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(directory + filename) as f:\n",
    "            data = json.load(f)\n",
    "            # go through the data and convert it to a numpy array\n",
    "            for row in data:\n",
    "                row_list_with_label = []\n",
    "                row_list_with_label.append(0)\n",
    "                for col in row:\n",
    "                    row_list_with_label.append([float(col[\"x\"]), float(col[\"y\"]), float(col[\"z\"])])\n",
    "            all_negative.append(row_list_with_label)   \n",
    "            \n",
    "np.save('negative.npy', np.array(all_negative))\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process JSON data into pandas dataframes and saved as tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the json files at specific directory\n",
    "\n",
    "\n",
    "directory = 'uncombined-training-data/time-freq-1-mil/1-milisecond-positive-json-data/'\n",
    "allPositiveFiles = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(directory + filename) as f:\n",
    "            # df.add(json.load(f))\n",
    "            allPositiveFiles.append(json.load(f))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "allDataframes = []\n",
    "for file in allPositiveFiles:\n",
    "    tempDf = pd.DataFrame(file)\n",
    "    for index, row in tempDf.iterrows():\n",
    "        for index2, col in row.iteritems():\n",
    "            if col != None:\n",
    "                dictionaryToArray = []\n",
    "                for i in col.values():\n",
    "                    dictionaryToArray.append(float(i))\n",
    "                tempDf.at[index, index2] = dictionaryToArray\n",
    "            else:\n",
    "                tempDf.at[index, index2] = [0,0,0]\n",
    "    allDataframes.append(tempDf)\n",
    "\n",
    "# combine all the dataframes into one\n",
    "df = pd.concat(allDataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# add one collumn dataframe at the begging of the dataframe\n",
    "\n",
    "\n",
    "\n",
    "# find the row with the most non zero values\n",
    "maxNonZero = 0\n",
    "for index, row in df.iterrows():\n",
    "    temp = 0\n",
    "    for index2, col in row.iteritems():\n",
    "        if index2 != 'Y':\n",
    "            if col != [0,0,0]:\n",
    "                temp += 1\n",
    "    if temp > maxNonZero:\n",
    "        maxNonZero = temp\n",
    "\n",
    "# find the row with the most zero values\n",
    "maxZero = 0\n",
    "for index, row in df.iterrows():\n",
    "    temp = 0\n",
    "    for index2, col in row.iteritems():\n",
    "        if index2 != 'Y':\n",
    "            if col == [0,0,0]:\n",
    "                temp += 1\n",
    "    if temp > maxZero:\n",
    "        maxZero = temp\n",
    "\n",
    "minNonZero = maxNonZero - maxZero\n",
    "\n",
    "print(\"what is the maxNonZero: \", maxNonZero)\n",
    "\n",
    "df.reindex(range(maxNonZero), fill_value=None)\n",
    "for index, row in df.iterrows():\n",
    "    for index2, col in row.iteritems():\n",
    "            if col != None and type(col) !=float:\n",
    "                pass\n",
    "            else:\n",
    "                df.at[index, index2] = [0,0,0]\n",
    "\n",
    "df.insert(0, 'Y', 1)\n",
    "\n",
    "# load all the negative json files at specific directory\n",
    "negativeDirectory = 'uncombined-training-data/time-freq-1-mil/1-milisecond-negative-json-data/'\n",
    "allNegativeFiles = []\n",
    "for filename in os.listdir(negativeDirectory):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(negativeDirectory + filename) as f:\n",
    "            allNegativeFiles.append(json.load(f))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "allNegativeDataframes = []\n",
    "for file in allNegativeFiles:\n",
    "    tempDf = pd.DataFrame(file)\n",
    "    for index, row in tempDf.iterrows():\n",
    "        for index2, col in row.iteritems():\n",
    "            if col != None:\n",
    "                dictionaryToArray = []\n",
    "                for i in col.values():\n",
    "                    dictionaryToArray.append(float(i))\n",
    "                tempDf.at[index, index2] = dictionaryToArray\n",
    "            else:\n",
    "                tempDf.at[index, index2] = [0,0,0]\n",
    "    allNegativeDataframes.append(tempDf)\n",
    "\n",
    "# combine all the dataframes into one\n",
    "negativeDf = pd.concat(allNegativeDataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "temp = []\n",
    "for index, row in negativeDf.iterrows():\n",
    "    split_rows = []\n",
    "    split_index = random.randint(minNonZero, maxNonZero)\n",
    "    start_index = 0\n",
    "    while split_index < len(row.values):\n",
    "        temp_row = row.values[start_index:split_index]\n",
    "        start_index = split_index\n",
    "        split_index = start_index + random.randint(minNonZero, maxNonZero)\n",
    "\n",
    "        allZero = True\n",
    "        for i in temp_row:\n",
    "            if i != [0,0,0]:\n",
    "                allZero = False\n",
    "                break\n",
    "        doesnt_contain_list = True\n",
    "        for i in temp_row:\n",
    "\n",
    "            if type(i) == float:\n",
    "                doesnt_contain_list = False  \n",
    "        \n",
    "        if allZero == False and doesnt_contain_list == True:\n",
    "            temp.append(temp_row)\n",
    "\n",
    "# convert the list to numpy array\n",
    "\n",
    "    \n",
    "expanded_negativeDf = pd.DataFrame(temp)\n",
    "expanded_negativeDf.reindex(range(maxNonZero), fill_value=0)\n",
    "\n",
    "for index, row in expanded_negativeDf.iterrows():\n",
    "    for index2, col in row.iteritems():\n",
    "            if col != None or col == 0 and type(col) !=float:\n",
    "                pass\n",
    "            else:\n",
    "                expanded_negativeDf.at[index, index2] = [0,0,0]\n",
    "\n",
    "\n",
    "expanded_negativeDf.insert(0, 'Y', 0)\n",
    "\n",
    "expanded_negativeDf.to_csv('negative.tsv', sep='\\t', index=False)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat([df, expanded_negativeDf], ignore_index=True)\n",
    "\n",
    "\n",
    "# save the maxNonZero and maxZero to a file called data_info.txt\n",
    "with open('data_info.txt', 'w') as f:\n",
    "    f.write(\"Max non zero: \" + str(maxNonZero) + \"\\n\")\n",
    "    f.write(\"Max zero: \" + str(maxZero) + \"\\n\")\n",
    "    f.write(\"Min non zero: \" + str(minNonZero) + \"\\n\")\n",
    "    f.write(\"Total rows: \" + str(len(df)) + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save dataframe to tab separated file\n",
    "df.to_csv('data.tsv', sep='\\t', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('time-series-data-mining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36938ddbb6c08077ca1515a91809541f7be305de7f4efe514c09144966008f42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
